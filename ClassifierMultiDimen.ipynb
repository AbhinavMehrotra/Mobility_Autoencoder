{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClassifierMultiDimen():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.frequency = {}\n",
    "        self.accuracy = -1\n",
    "        self.prf = []\n",
    "        self.conf_matrix = []\n",
    "        \n",
    "        \n",
    "    def classify(self, x_train, y_train, x_test, y_test): \n",
    "#         print 'Len of x_train', len(x_train)\n",
    "#         print 'Len of y_train', len(y_train)\n",
    "#         print 'Len of x_test', len(x_test)\n",
    "#         print 'Len of y_test', len(y_test)\n",
    "        \n",
    "        if len(x_train) != len(y_train) or len(x_test) != len(y_test):\n",
    "            raise ValueError(\"Length mismatch of data and labels\") \n",
    "        \n",
    "        ### compute frequency of labels in train data ###\n",
    "        self.frequency = dict([(i,0) for i in np.unique(y_train)])\n",
    "        for number in y_train:\n",
    "            self.frequency[number]+=1 \n",
    "        for key in self.frequency:\n",
    "            self.frequency[key] = float(self.frequency[key]) / len(y_train)\n",
    "\n",
    "            \n",
    "        print \"Number of samples:\", len(x_train)\n",
    "        print \"Number of features:\", len(x_train[0])\n",
    "        \n",
    "        ### setting up classifier ###\n",
    "        clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "        clf.fit(x_train, y_train) \n",
    "\n",
    "        ### compute model performance for test data###\n",
    "        y_true = y_test\n",
    "        y_pred = clf.predict(x_test)\n",
    "        self.accuracy = sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)\n",
    "        self.prf = sklearn.metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, pos_label=1, average='weighted', sample_weight=None)\n",
    "        self.conf_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "        print \"Performance computed: \", self.conf_matrix\n",
    "        \n",
    "        \n",
    "    \n",
    "#     # x_data should have only columns for data\n",
    "#     def classify_kfold(self, x_data, y_data, encode):\n",
    "#         k_frequency = []\n",
    "#         k_accuracy = []\n",
    "#         k_prf = []\n",
    "#         k_conf_matrix = []\n",
    "#         for i in range(k):\n",
    "#             print(\"Iteration \", i)\n",
    "            \n",
    "#             # setting up train & test data\n",
    "#             train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(\n",
    "#                 x_data, y_data, test_size=0.2, random_state=i)\n",
    "        \n",
    "#             # return is there not enough unique labels\n",
    "#             if len(set(train_labels)) != len(set(test_labels)):\n",
    "#                 print 'Not enough samples for this iteration'\n",
    "#                 continue\n",
    "                \n",
    "#             self.classify(train_data, train_labels, test_data, test_labels, encode)\n",
    "#             k_frequency.append(self.frequency)\n",
    "#             k_accuracy.append(self.accuracy)\n",
    "#             k_prf.append(self.prf)\n",
    "#             k_conf_matrix.append(self.conf_matrix)\n",
    "        \n",
    "#         self.frequency = k_frequency\n",
    "#         self.accuracy = k_accuracy\n",
    "#         self.prf = k_prf\n",
    "#         self.conf_matrix = k_conf_matrix\n",
    "        \n",
    "        \n",
    "       \n",
    "    # x_data should have two columns for user and data\n",
    "    def classify_leave_one_out(self, x_data_list, y_data, samples_req, users, encode=True):\n",
    "        # get list of users\n",
    "        self.users = users\n",
    "        \n",
    "        k_frequency = []\n",
    "        k_accuracy = []\n",
    "        k_prf = []\n",
    "        k_conf_matrix = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(self.users)):\n",
    "        #for i in [1,2,5]:\n",
    "            current_user = self.users[i]\n",
    "            print \"Iteration \", i, current_user\n",
    "            \n",
    "            # list for merging all data representations\n",
    "            all_train_data, all_test_data, all_train_labels, all_test_labels = [], [], [], []\n",
    "            \n",
    "            # setting up train & test data from each dataset\n",
    "            for i in range(len(x_data_list)): \n",
    "                x_data = x_data_list[i]\n",
    "                \n",
    "                # indices for current user\n",
    "                cu_indices = [i  for i in range(len(x_data)) if x_data[i][0] == current_user]\n",
    "\n",
    "                # N pos & neg index for this user [to be added for training]\n",
    "                cu_pos_index, cu_neg_index = [],[]\n",
    "                for cu_index in cu_indices:\n",
    "                    if y_data[cu_index] == 1 and len(cu_pos_index) < samples_req:\n",
    "                        cu_pos_index.append(cu_index)\n",
    "                    if y_data[cu_index] == -1 and len(cu_neg_index) < samples_req:\n",
    "                        cu_neg_index.append(cu_index)\n",
    "                    if len(cu_pos_index) == samples_req and len(cu_neg_index) == samples_req:\n",
    "                        break    \n",
    "                cu_indices = [i for i in cu_indices if i not in cu_pos_index and i not in cu_neg_index]\n",
    "\n",
    "                if len(cu_indices) < 10: # or len(cu_pos_index) < samples_req or len(cu_neg_index) < samples_req:\n",
    "                    print 'Not enough samples for this iteration'\n",
    "                    print 'Total-Pos-Neg labels', len(cu_indices) #, len(cu_pos_index), len(cu_neg_index)\n",
    "                    break \n",
    "\n",
    "\n",
    "                train_data = [x_data[i][1]  for i in range(len(x_data)) if i not in cu_indices]\n",
    "                test_data = [x_data[i][1]  for i in range(len(x_data)) if i in cu_indices]\n",
    "                train_labels = [y_data[i]  for i in range(len(y_data)) if i not in cu_indices]\n",
    "                test_labels = [y_data[i]  for i in range(len(y_data)) if i in cu_indices]\n",
    "\n",
    "                # return is there not enough unique labels\n",
    "                if len(set(train_labels)) != len(set(test_labels)):\n",
    "                    print 'Not enough samples for this iteration'\n",
    "                    print 'Train-test labels', len(set(train_labels)), len(set(test_labels))\n",
    "                    break\n",
    "                \n",
    "                        \n",
    "                ### encode data  ###\n",
    "                if encode == True:\n",
    "                    # train AE (only on train data)\n",
    "                    input_layer_size = len(train_data[0])\n",
    "                    ae = AETrainer(input_layer_size)\n",
    "                    ae.set_data(train_data, train_labels)\n",
    "                    ae.train_model()\n",
    "                    encoded_data = ae.encode_data(train_data)\n",
    "                    train_data = encoded_data.data.numpy().tolist()\n",
    "                    encoded_data = ae.encode_data(test_data)\n",
    "                    test_data = encoded_data.data.numpy().tolist()\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                # merge data\n",
    "                for j in range(len(train_data)):\n",
    "                    if len(all_train_data) == j:\n",
    "                        all_train_data.append(train_data[j])\n",
    "                    else:\n",
    "                        for td in train_data[j]:\n",
    "                            all_train_data[j].append(td)\n",
    "                for j in range(len(test_data)):\n",
    "                    if len(all_test_data) == j:\n",
    "                        all_test_data.append(test_data[j])\n",
    "                    else:\n",
    "                        for td in test_data[j]:\n",
    "                            all_test_data[j].append(td)\n",
    "                if len(all_train_labels) == 0:\n",
    "                        all_train_labels = train_labels\n",
    "                if len(all_test_labels) == 0:\n",
    "                        all_test_labels = test_labels\n",
    "            \n",
    "            # go to next user if no data is computed for this user\n",
    "            if len(all_train_data) == 0 or len(all_test_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            self.classify(all_train_data, all_train_labels, all_test_data, all_test_labels)\n",
    "            k_frequency.append(self.frequency)\n",
    "            k_accuracy.append(self.accuracy)\n",
    "            k_prf.append(self.prf)\n",
    "            k_conf_matrix.append(self.conf_matrix)\n",
    "\n",
    "            self.frequency = k_frequency\n",
    "            self.accuracy = k_accuracy\n",
    "            self.prf = k_prf\n",
    "            self.conf_matrix = k_conf_matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClassifierMultiDimenHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_svm_accuracy(xy_data_list, is_leave_one_user, samples_req=3, users=[]):\n",
    "        # setting up the data\n",
    "        y_data = [d[4] for d in xy_data_list[0]]\n",
    "        x_data = []\n",
    "        for xy_data in xy_data_list:\n",
    "            if is_leave_one_user == True:\n",
    "                x_data.append([[d[0], d[5]] for d in xy_data])\n",
    "            else:\n",
    "                x_data.append([d[5] for d in xy_data])\n",
    "\n",
    "        # classify\n",
    "        model = ClassifierMultiDimen()\n",
    "        if is_leave_one_user == True:\n",
    "            model.classify_leave_one_out(x_data, y_data, samples_req, users)\n",
    "        else:\n",
    "            model.classify_kfold(x_data, y_data)\n",
    "\n",
    "        return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
